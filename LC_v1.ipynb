{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balu337/LendingClubRepo/blob/master/LC_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ImportStatments**"
      ],
      "metadata": {
        "id": "8mKKWCDAJl63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical and Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extra\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows',200)"
      ],
      "metadata": {
        "id": "3-ctFPQ9KcKq"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "6FcfjSDpXEdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecba7be-1ac1-4701-d1d2-5d4b130d6d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/MyDrive/IITB_AIML/1_Statistics/LendingClubCaseStudy/loan.csv\"\n",
        "#filepath=\"/content/drive/MyDrive/LendingClub/loan.csv\"\n",
        "\n",
        "\n",
        "df = pd.read_csv(filepath)"
      ],
      "metadata": {
        "id": "vzokbC06KzMo",
        "outputId": "8a5823e7-9296-4748-afce-1348848c67ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/LendingClub/loan.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-d6236cb16432>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/LendingClub/loan.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyze Raw Data**\n",
        "\n",
        "Check column by column using Data Dictionary and get unerstanding the data ( content and type )"
      ],
      "metadata": {
        "id": "6a_SW8nlnoB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "gixPQHEwOSau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Description of dataset\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "zqegu4nMO5Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display information about dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "h0CpjF0OcVfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find datatypes of columns\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "CI0prZOacZ6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get All Column Names\n",
        "\n",
        "col= list(df.columns)\n",
        "print(\"# Columns are \", len(col))\n",
        "print(\"Columns are \", col)"
      ],
      "metadata": {
        "id": "CX4QKQ7_Q5aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating new dataframe for Analysis"
      ],
      "metadata": {
        "id": "Nc03A5Shd2V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unwanted columns\n",
        "\n",
        "# #After basic analysis columns after [ annual_inc_joint ] are not useful as there is not data.\n",
        "\n",
        "# print(\"-->\",col[53])\n",
        "# columns_removed=col[53:]\n",
        "# print(\"removed col \",columns_removed)\n",
        "# df1=df.drop(columns_removed,axis=1)\n",
        "\n",
        "# Lets drop columns with all null values\n",
        "df1=df.dropna(axis=1, how='all')\n",
        "df1.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "egU8Di7AR2fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we observe there are few columns have sigle values, those are not helpful for analysis lets drop them\n",
        "\n",
        "#check how many single value columns are there\n",
        "# print((df1.nunique()==1).sum())\n",
        "# print(df1[nunique()==1])\n",
        "un=df1.nunique()==1\n",
        "unc=un[un].index\n",
        "print(unc.tolist())"
      ],
      "metadata": {
        "id": "WnkC9NW9dwMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get  Column afte dropping columns after annual_inc_joint\n",
        "\n",
        "col1= list(df1.columns)\n",
        "print(\"# Columns are \", len(col1))\n",
        "print(\"Columns are \", col1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ohSUI_PbS8mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "B3AzwU74OZ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().mean()*100"
      ],
      "metadata": {
        "id": "0J6z2MtKPDU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.application_type.value_counts()"
      ],
      "metadata": {
        "id": "kZdKRlO-PDez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.policy_code.value_counts()"
      ],
      "metadata": {
        "id": "f_pyZyHCPDiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing columns with only 1 value in all rows\n",
        "\n",
        "df1=df1.drop(['application_type','policy_code','mths_since_last_major_derog'],axis=1)"
      ],
      "metadata": {
        "id": "M0LxmZ4CPDlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().mean()*100"
      ],
      "metadata": {
        "id": "0EoBQcLEPDoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.emp_title.unique()"
      ],
      "metadata": {
        "id": "HD2-30SUPDq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkRES25bPDuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions"
      ],
      "metadata": {
        "id": "xgowVhOAYJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do we need Emp title ?\n"
      ],
      "metadata": {
        "id": "uZJkSGb4PDxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFRsmT8BPD0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbozXsj1PD39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LS3JDM6SPECi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cleansing Data**\n",
        "\n",
        "\n",
        "* Find Shape of data\n",
        "* Check for Null columns and cells\n",
        "* For numeric data use either median ( mostly ) or mode as required\n",
        "* For categorical data use Mode"
      ],
      "metadata": {
        "id": "hlXJ42HKoLWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#emp_lenght is  2.706650 null. Filling it with Median\n",
        "\n",
        "#examine the data in the column\n",
        "\n",
        "df1.emp_length.unique()\n",
        "df1.emp_length.nunique()\n",
        "df1.emp_length.value_counts()\n"
      ],
      "metadata": {
        "id": "I32gAd_mYrQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Object to int\n",
        "\n",
        "def getYears(x):\n",
        "  if isinstance(x, str):\n",
        "    xlist=x.split(\" \")\n",
        "  else:\n",
        "    xlist = []\n",
        "\n",
        "\n",
        "  if(len(xlist) == 3):\n",
        "    ans=0\n",
        "  elif (len(xlist) == 2):\n",
        "    ans=int(x.split(\" \")[0][:2])\n",
        "  elif pd.isna(x):\n",
        "    ans=x\n",
        "  else:\n",
        "      ans=int(x)\n",
        "  return ans\n",
        "\n",
        "\n",
        "# Convertng Object to int\n",
        "df1['emp_length'] =  df1['emp_length'].apply(getYears)\n"
      ],
      "metadata": {
        "id": "-qDyiD8-ZfW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.emp_length.unique()\n",
        "df1.emp_length.value_counts()"
      ],
      "metadata": {
        "id": "wCHtemcrdNP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the median of the emp_length\n",
        "import math\n",
        "\n",
        "expmedian= math.trunc(int(df1.emp_length.median()))\n",
        "print(math.trunc(expmedian))\n",
        "\n",
        "df1.emp_length.isnull().sum()\n",
        "\n",
        "df1.emp_length=df1.emp_length.fillna(math.trunc(expmedian))\n",
        "df1.emp_length.value_counts()"
      ],
      "metadata": {
        "id": "mu-Kl7G5e0N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().mean()*100"
      ],
      "metadata": {
        "id": "VcgFca2ygl8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing columns as we might not be using it.\n",
        "#Check why there is an error commenting for now\n",
        "#df1=df1.drop(['mths_since_last_record','next_pymnt_d'],axis=1)"
      ],
      "metadata": {
        "id": "60S_d9fZrhkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of mths_since_last_delinq\n",
        "df1.mths_since_last_delinq.value_counts()"
      ],
      "metadata": {
        "id": "nKE-bFJ3kVG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df1.mths_since_last_delinq.value_counts().sum()  #14035\n",
        "df1.mths_since_last_delinq.isnull().sum()  #25682"
      ],
      "metadata": {
        "id": "lt1Wy5f_jZ_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delMedian=df1.mths_since_last_delinq.median()\n",
        "\n",
        "df1.mths_since_last_delinq =df1.mths_since_last_delinq.fillna(delMedian)"
      ],
      "metadata": {
        "id": "MXXz6gJJjxD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.mths_since_last_delinq.value_counts().sum() #39717\n",
        "df1.mths_since_last_delinq.isnull().sum()  #0"
      ],
      "metadata": {
        "id": "3aluyN1Fkkla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Univariate Analysis**\n",
        "\n",
        "* Identify the columns to be Analyzed\n",
        "* Generate plots ( Bar , Box Plot and Histogram )\n",
        "* Review each column and *remove outliers\n"
      ],
      "metadata": {
        "id": "DJAEQSMOpUFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Segmentation"
      ],
      "metadata": {
        "id": "2a93PWj7lYiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(3)"
      ],
      "metadata": {
        "id": "xfwsimAulfym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "UOauokP6lncj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols=[ 'grade', 'sub_grade','home_ownership', 'verification_status',\n",
        "       'issue_d', 'loan_status', 'pymnt_plan','zip_code', 'addr_state','open_acc', 'pub_rec',]\n",
        "num_cols=['loan_amnt','funded_amnt','funded_amnt_inv', 'term', 'int_rate', 'installment',\n",
        "          'emp_length',  'annual_inc','dti', 'delinq_2yrs','inq_last_6mths', 'mths_since_last_delinq',\n",
        "          'revol_bal','revol_util', 'total_acc','out_prncp',\n",
        "          'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv','total_rec_prncp',\n",
        "          'total_rec_int', 'total_rec_late_fee', 'recoveries','collection_recovery_fee', ]\n",
        "extra_cols=['id', 'member_id',  'emp_title','url', 'desc', 'purpose',\n",
        "       'title','earliest_cr_line',   'initial_list_status', 'last_pymnt_d', 'last_pymnt_amnt',\n",
        "       'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med']"
      ],
      "metadata": {
        "id": "CAxF1UeJkzn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Columns Analysis"
      ],
      "metadata": {
        "id": "_9Fl4UXft60E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in num_cols:\n",
        "    sns.histplot(x=df1[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CY57s7eit5lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collection recovery fee analysis\n",
        "df1.collection_recovery_fee.value_counts()  #collection_recovery_fee"
      ],
      "metadata": {
        "id": "vM6ZADMEvYxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(x=df1['collection_recovery_fee'], bins = range(0,10,1) )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ufFXsEO9vmZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bivariate Analysis**\n",
        "\n",
        "* Identify the pairs of columns to be Analyzed\n",
        "* Generate cattered plots plots and identify the dependency\n"
      ],
      "metadata": {
        "id": "Zrp6858BJDXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multivariate Analysis**\n",
        "\n",
        "## For all Numeric columns plot a heat map and identify the corelation\n",
        "\n",
        "\n",
        "* *Correlation represents strength of relationship between variables*\n",
        "* *Correlation lies in the range of -1 to 1*\n",
        "* *Negative correlation  (0 to -1) shows inverse relationship*\n",
        "* *Positive correlation (0 to 1) shows direct relationship*\n",
        "* *0 correlation represents no relationship. *italicized text*"
      ],
      "metadata": {
        "id": "2bcRToJQJUwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Univariate Analysis --> Analysis with Single variable\n",
        "--> Mean, Median, Max, Min, Std, Variance, Count\n",
        "--> Distribution (Histogram,Distplot,Countplot,boxplot)\n",
        "## Bivaraite Analsyis --> Analysis with two variables\n",
        "--> Relationship between two variables (Scatterplot, boxplot,barplot etc)\n",
        "## Multivariate Analysis\n",
        "--> Relationship between more than variables (Heatmap etc)"
      ],
      "metadata": {
        "id": "TDDXwJqjLAZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coomit at 12.15"
      ],
      "metadata": {
        "id": "svXtPhRiWYqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commiting at 12.10"
      ],
      "metadata": {
        "id": "AEXcN_dZVQ6i"
      }
    }
  ]
}